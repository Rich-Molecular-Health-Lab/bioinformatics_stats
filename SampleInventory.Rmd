---
title: "Sample/Library Inventory"
author: "Alicia Rich"
output:
  html_document:
    toc: true
    toc_location: "before"
    toc_depth: 4
    number_sections: false
    toc_float: true
    code_folding: "hide"
    fig_caption: true
editor_options: 
  chunk_output_type: inline
params:
  taxon: "loris"
                     
---

```{r setup, echo = FALSE, message=FALSE, warning=FALSE}
global             <- config::get(config = "default")
micro              <- config::get(config = "microbiome")
swan               <- config::get(config = "swan")
notebooks          <- config::get(config = "notebooks")

source(paste0(global$functions))
source(paste0(global$packages))
source(paste0(global$conflicts))
source(paste0(global$inputs))
source(paste0(swan$functions))
```


# Intro

This script streamlines and standardizes our handling of the steps taken to reach each dataset from an original sampleset. You will export some standardized csv and tsv tables for easy importing and manipulation with our other workflows.

## Files Needed

To start, you should have four categories of csv files (I download the first three from working google spreadsheets, and the fourth category is a series of files automatically generated by each MinION sequencing run). Those files and their list of column headers to be used are as follows (note: it is fine to have extra columns, but you must at least have these to run the script as is):  

1. Libraries
  - SequenceID	
  - Pipeline	
  - LibraryTube	
  - LibraryBarcode	
  - ExtractID	
  - Final.Library.Concentration	
  - Volume.Added.to.Pool.(uL)	
  - Seq.ID	
  - Run.ID	
  - LibraryTubeID	
2. Extracts
  - ExtractID	
  - ExtractDate	
  - ExtractedBy	
  - ExtractType	
  - ExtractKit	
  - SampleID	
  - ExtractConcentration	
  - ExtractBox	
  - ExtractNotes
3. Samples
  - SampleID
  - SampleSubject
  - SampleDate
  - SampleCollectedBy
  - SampleNotes
4.  Barcode Alignments (1 file per Run.ID)
  - barcode
  - alias
  - type
  - target_unclassified
  - qcquisition_run_id
  - protocol_group_id
  - sample_id
  - flow_cell_id
  - started
  
## Other Configuration Settings

### Taxon in Params

You can use the taxon setting under params in the header of this script to select which taxon you will be working with. So long as the same name is used consistently, this should automatically filter for that name (e.g., loris or marmoset). 

### Sequencing Run Lists

Below is a chunk to generate a list of formatted codes for each available sequencing run to date, separated by taxa/samplesets (currently just for loris and marmoset). Make sure the end number matches the highest integer we have for that sampleset to date. The next chunk will format a list of all subject names for whichever taxon you identified in the header.

```{r, message=FALSE, warning=FALSE}
seqruns <- list(
  loris     = as.list(paste0("hdz", 1:18)),
  marmoset  = as.list(sprintf("cm%03d", 1:10))
)

subject_list <- keep_at(subjects, paste0(params$taxon)) %>% list_flatten(name_spec = "{inner}")
```

### File Paths

Next, you should make sure your config.yml file contains the path to locate each of the files you will be using. Below is an example excerpt from my config file. 

```
sample_sheets:
  compilations:
    loris:    "../bioinformatics_stats/dataframes/sample_sheet/loris/hdz_combined_sample_sheet.csv"
    marmoset: "../bioinformatics_stats/dataframes/sample_sheet/marmoset/cm_combined_sample_sheet.csv"
  hdz1:  "../bioinformatics_stats/dataframes/sample_sheet/loris/hdz1_sample_sheet.csv"
  hdz2:  "../bioinformatics_stats/dataframes/sample_sheet/loris/hdz2_sample_sheet.csv"
  hdz3:  "../bioinformatics_stats/dataframes/sample_sheet/loris/hdz3_sample_sheet.csv"
  cm001: "../bioinformatics_stats/dataframes/sample_sheet/marmoset/cm001_sample_sheet.csv"
  cm002: "../bioinformatics_stats/dataframes/sample_sheet/marmoset/cm002_sample_sheet.csv"
  cm003: "../bioinformatics_stats/dataframes/sample_sheet/marmoset/cm003_sample_sheet.csv"

barcode_alignments:
  compilations:
    loris: "../labwork/minion_data/barcode_alignments/loris/hdz_combined_barcode_alignment.tsv"
    marmoset: "../labwork/minion_data/barcode_alignments/marmoset/cm_combined_barcode_alignment.tsv"
  hdz1:  "../labwork/minion_data/barcode_alignments/loris/hdz1_barcode_alignment.tsv"
  hdz2:  "../labwork/minion_data/barcode_alignments/loris/hdz2_barcode_alignment.tsv"
  hdz3:  "../labwork/minion_data/barcode_alignments/loris/hdz3_barcode_alignment.tsv"
  cm001: "../labwork/minion_data/barcode_alignments/marmoset/cm001_barcode_alignment.tsv"
  cm002: "../labwork/minion_data/barcode_alignments/marmoset/cm002_barcode_alignment.tsv"
  cm003: "../labwork/minion_data/barcode_alignments/marmoset/cm003_barcode_alignment.tsv"
  
loris:
  libraries_csv: "../data/libraries_loris.csv"
  compilation_csv: "../data/compilation_loris.csv"
  extracts_csv: "../data/extracts_loris.csv"
  samples_csv: "../data/samples_loris.csv"
  sample_sheet: "../bioinformatics_stats/loris/dataframes/sample_sheet/"
  taxonomy_list: "../bioinformatics_stats/loris/dataframes/taxonomy_list/"

marmoset:
  libraries_csv: "../data/libraries_marmoset.csv"
  compilation_csv: "../data/compilation_marmoset.csv"
  extracts_csv: "../data/extracts_marmoset.csv"
  samples_csv: "../data/samples_marmoset.csv"
  sample_sheet: "../bioinformatics_stats/marmoset/dataframes/sample_sheet/"
  taxonomy_list: "../bioinformatics_stats/marmoset/dataframes/taxonomy_list/"

```


Note that I also include paths to files that this script will create. If the file is already there, then it will be overwritten, if not, it will be created there. Run the code below to set up your paths from the config file for the working taxon you identified in the header:

```{r}
loris              <- config::get(config = "loris")
marm               <- config::get(config = "marmoset")
path               <- config::get(config = params$taxon)
barcode_alignments <- config::get(config = "barcode_alignments")
sample_sheets      <- config::get(config = "sample_sheets")
```

# Script

The chunk below is duplicated above. I am adding it here to run the full setup chunk again in case you skipped past the intro material:

```{r, include = F}
global             <- config::get(config = "default")
micro              <- config::get(config = "microbiome")
read_processing    <- config::get(config = "read_processing")
notebooks          <- config::get(config = "notebooks")

source(paste0(global$functions))
source(paste0(global$packages))
source(paste0(global$conflicts))
source(paste0(global$inputs))
source(paste0(read_processing$functions))

seqruns <- list(
  loris     = as.list(paste0("hdz", 1:18)),
  marmoset  = as.list(sprintf("cm%03d", 1:10))
)

subject_list <- keep_at(subjects, paste0(params$taxon)) %>% list_flatten(name_spec = "{inner}")


loris              <- config::get(config = "loris")
marm               <- config::get(config = "marmoset")
path               <- config::get(config = params$taxon)
barcode_alignments <- config::get(config = "barcode_alignments")
sample_sheets      <- config::get(config = "sample_sheets")
```


## Barcode Alignments


```{r, message=FALSE, warning=FALSE}
barcodes <- imap(seqruns[[paste0(params$taxon)]], ~ {
  map(.x, ~ read.table(barcode_alignments[[.x]], header = T) %>% mutate(seqrun = .x)) 
}) %>%
    bind_rows() %>%
                        as_tibble() %>%
                        filter(barcode     != "unclassified") %>%
                        mutate(SeqDateTime  = as_datetime(started)) %>%
                        mutate(SeqDate      = floor_date(SeqDateTime, unit = "day")) %>%
                        mutate(SeqRunID     = str_replace_all(sample_id, "pool1", "PL001")) %>%
                      mutate(LibraryCode    = str_squish(str_trim(seqrun      , "both")),
                             FlowCellSerial = str_squish(str_trim(flow_cell_id, "both"))
                             ) %>%
                      mutate(LibraryBarcode  = as.numeric(str_remove_all(barcode, "16S|barcode0|barcode"))) %>%
                        select(LibraryCode,
                               LibraryBarcode,
                               reads_unclassified = target_unclassified,
                               FlowCellSerial,
                               protocol_group_id,
                               SeqRunID,
                               SeqDate,
                               SeqDateTime)

write.table(barcodes, barcode_alignments$compilations[[paste0(params$taxon)]],
            row.names = F,
            sep = "\t")
```

## Sequencing Runs

```{r, message=FALSE, warning=FALSE}
seqrun.tbl <- read.csv(path$seqruns_csv, header = T) %>% 
  mutate(SampleSet       = if_else(str_detect(Pooled.Library.Code, "CM"), "marmoset", "loris"),
         LibraryCode     = str_to_lower(Pooled.Library.Code),
         LibPrepWorkflow = case_when(
           str_detect(Kit, "LSK") & Pipeline == "16S" ~ "lsk16s",
           Pipeline == "Host mtDNA"                   ~ "lskadaptive",
           str_detect(Kit, "SQK-16S") & Pipeline == "16S" ~ "rapid16s"),
         LibPrepDate     = mdy(Run.Date),
         SeqRunDate      = ymd(str_remove_all(str_trim(Run.ID, "both"), "MIN_16_|MIN_16-|MIN_MT_"))) %>%
  mutate(LibraryCode     = str_replace_all(LibraryCode, "pl00|pl0", "hdz"),
         strands         = 2,
         fragment_type   = if_else(Pipeline == "16S", 3, 1),
         Length          = if_else(Pipeline == "16S", 1500, 10000),
         InputMassStart  = if_else(Pipeline == "16S", 10, 1000),
         TemplateVolPrep = if_else(LibPrepWorkflow == "rapid16s", 15, 47),
         PoolSamples     = if_else(Pipeline == "16S", "yes", "no"),
         InputMassFinal  = 50
         ) %>%
  select(
         SampleSet,
         LibraryCode,
         LibPrepDate,
         LibPrepWorkflow,
         LibPrepKit      = Kit,
         FlowCellSerial  = Flow.Cell.ID,
         FlowCellType    = Flow.Cell.Type,
         FlongleAdapter  = Flongle.Adapter,
         SeqDevice       = Sequencer,
         strands,
         fragment_type,
         Length,
         InputMassStart,
         TemplateVolPrep,
         PoolSamples,
         InputMassFinal)
```


## Sample Records

```{r}
samples     <- read.csv(path$samples_csv, header = T) %>% 
                      filter(str_starts(SampleID, "\\w+")) %>% 
                      select(-SampleBox)  %>%
                      mutate(SampleID = str_squish(str_trim(SampleID, "both"))) %>% distinct() %>%
                      mutate(CollectionDate     = mdy(SampleDate),
                             Subject            = str_squish(str_trim(SampleSubject)),
                             .keep = "unused") %>% distinct() %>%
                      mutate(Subj_Certainty = if_else(Subject %in% subject_list, "yes", "no")) %>%
                      mutate(Subject        = str_remove_all(Subject, "\\?"))
```

## DNA Extract Records

We will also join the previous sample records to this table at the end of the chunk.

```{r}
extracts <- read.csv(path$extracts_csv, header = T) %>% 
  filter(str_starts(SampleID, "\\w+")) %>%
  mutate(SampleID        = if_else(str_detect(SampleID, "#N/A"), "ExtractControl", SampleID)) %>%
  mutate(SampleID = str_squish(str_trim(SampleID, "both")),
         ExtractID= str_squish(str_trim(ExtractID, "both")),
         ExtractDate       = mdy(ExtractDate)) %>%
  mutate(ExtractConc       = str_remove_all(ExtractConcentration, ">"), .keep = "unused") %>%
  mutate(ExtractConc = if_else(str_detect(ExtractConc, "Higher"), "100", ExtractConc),
         ExtractConc = if_else(str_detect(ExtractConc, "HIGHER"), "100", ExtractConc),
         ExtractConc = if_else(ExtractConc == "LOW", "0", ExtractConc),
         ExtractConc = if_else(ExtractConc == "", NA, ExtractConc)) %>%
  mutate(ExtractConc = round(as.numeric(ExtractConc), 1))  %>% filter(ExtractType == "DNA") %>%
  select(-ExtractType) %>%
  left_join(samples) %>% distinct()
```

## Libraries and Combining all Records

```{r}
compilation <- read.csv(path$libraries_csv, header = T)  %>% 
  filter(str_starts(SequenceID, "\\w+") & Seq.ID != "#N/A") %>%
  mutate(LibraryCode     = str_to_lower(Seq.ID)) %>%
  mutate(LibraryCode     = str_replace_all(LibraryCode, "pl00|pl0" , "hdz"),
         SampVolPool     = round(as.numeric(Volume.Added.to.Pool..uL.), 0),
         LibraryBarcode  = as.numeric(str_remove_all(LibraryBarcode, "16S|barcode0|barcode"))) %>%
  mutate(TotalPoolVol    = sum(SampVolPool), .by = LibraryCode) %>%
  mutate(BeadVol         = TotalPoolVol * 0.6) %>%
  select(SequenceID,
         LibraryCode,
         LibraryTube,
         LibraryBarcode,
         ExtractID,
         SampVolPool,
         TotalPoolVol,
         BeadVol,
         Conc_QC2    = Final.Library.Concentration) %>%
  left_join(barcodes, by = join_by(LibraryCode, LibraryBarcode)) %>%
  left_join(seqrun.tbl, by = join_by(LibraryCode, FlowCellSerial)) %>%
  left_join(extracts, by = join_by(ExtractID)) %>% distinct() %>%
  arrange(LibraryCode, LibraryBarcode)
```

### Exporting a Spreadsheet with Records

```{r, message=FALSE, warning=FALSE}
write.table(compilation,
            path$compilation,
            row.names = F,
            sep = "\t")
```


## Counting Replicates

```{r}
count.extracts    <- extracts %>% select(ExtractID, SampleID) %>% distinct() %>% 
  group_by(SampleID)  %>% 
  mutate(n_dna_extracts = n_distinct(ExtractID)) %>% ungroup() %>% select(-ExtractID)

count.libraries <- compilation %>% select(SequenceID, ExtractID, SampleID) %>% distinct() %>% 
  group_by(ExtractID) %>% mutate(n_16s_extract = n_distinct(SequenceID)) %>% ungroup() %>%
  group_by(SampleID)  %>% mutate(n_16s_sample  = n_distinct(SequenceID)) %>% ungroup() %>% select(-SequenceID)
```

## Exporting SampleSheets formatted for Dorado

```{r, message=FALSE, warning=FALSE}
samplesheet <- compilation %>%
                      mutate(barcode = if_else(LibraryBarcode < 10, 
                                               str_glue("barcode0", "{LibraryBarcode}"),
                                               str_glue("barcode" , "{LibraryBarcode}"))) %>%
                      select(flow_cell_id  = FlowCellSerial,
                             experiment_id = protocol_group_id,
                             kit           = LibPrepKit,
                             barcode,
                             alias         = SequenceID,
                             seqrun        = LibraryCode)

write.table(samplesheet, 
          sample_sheets$compilations[[paste0(params$taxon)]],
          row.names = F,
          quote     = F,
          sep       = ",")
```

### Splitting Samplesheet to Individual Files for Each Run


```{r, echo = FALSE, comment=FALSE, warning=FALSE}
samplesheet.nested <- samplesheet %>% nest(.by = seqrun) %>%
  deframe()

imap(samplesheet.nested, ~ {
  write.table(.x, (sample_sheets[[.y]]),
          row.names = F,
          quote     = F,
          sep       = ",")
})
```



# Next Step

>Now you should proceed to the Read Processing workflow to begin basecalling the sequencing run.
