---
title: "Loris Microbiome Project Results Overview - IN PROGRESS"
author: "Alicia Rich"
output:
  html_document:
    theme:
      bootswatch: litera
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    code_folding: "show"
    fig_caption: true
    df_print: paged
params:
  sampleset: "loris"
                     
---

### First use: Setting up BEEM

MicroEco's tutorial [guided us through installation of several dependencies, including BEEM-static](https://chiliubio.github.io/microeco_tutorial/intro.html#dependence), but to work with true longitudinal data, we want to use the original BEEM package instead. This is where microeco's [*mecodev* package](https://chiliubio.github.io/microeco_tutorial/mecodev-package.html) comes in handy. Mecodev provides a set of extended classes based on the microeco package, including *trans_ts*, a class designed for handling time-series data.

#### Install mecodev and dependencies

>I am following the linux/mac instructions. See the microeco tutorial for windows-specific code.

```{r, eval = FALSE}
# If devtools package is not installed, first install it
install.packages("devtools")
```

##### mecodev

```{r, eval = FALSE}
devtools::install_github("ChiLiubio/mecodev")
```

##### Dependencies

```{r, eval = FALSE}
# For linux or mac
install.packages("doMC")
# Then install the following packages
install.packages("lokern")
install.packages("monomvn")
install.packages("pspline")
devtools::install_github('csb5/beem')
```


```{r, message = FALSE}
global             <- config::get(config = "default")

here::i_am("ExploreResults_LorisMicrobiome.Rmd")
source(here::here(global$setup))
1

for (file in micro$micro_scripts) {
  source(here(file))
}

source(here(path$metadata$key))
source(here(path$metadata$factors))

dataset_dir <- path$microeco$dataset

theme_set(theme_classic())
thematic_rmd()
thematic_on(accent = "#8785B2FF", fg = "black")
```

# Read in Data

I have written several custom functions to expedite some of the functions that I reuse multiple times for data sets across different sample and taxon subsets. The loop below will use one of those functions to read the microeco datasets that I built using the [MicroEcoDataPrep](MicroEcoDataPrep.html) script.  
  
This code makes use of the dataset paths referenced in my config.yaml file. To see the full path (relative to the repository base directory), refer to the relative syntax in this script and the config file below.  

```{r, echo = FALSE}
page_fluid(
    accordion(
      open = FALSE,
      accordion_panel(
        "Show/Hide Config File (config.yml)",
        tagList(tags$pre(includeText("config.yml")))
    )
  )
)
```



```{r}
# Define dataset categories
dataset_types <- c("tax", "function")
tax_levels    <- c("species", "genus", "family", "order", "class", "phylum")
func_levels   <- c("kegg", "fpt", "njc")
datasets      <- c("main", "culi", "warb")

# Create an empty list to store all datasets
microtable_datasets <- list()

# Helper function to safely read files
safe_read <- function(file, ...) {
  if (file.exists(file)) {
    return(read.table(file, ...))
  } else {
    warning(paste("File missing:", file))
    return(NULL)
  }
}

# Loop through dataset types (taxonomic and functional)
for (data_type in dataset_types) {
  levels <- if (data_type == "tax") tax_levels else func_levels
  
  for (level in levels) {
    for (dataset in datasets) {
      # Extract dataset path from config
      if (!is.null(dataset_dir[[dataset]][[level]])) {
        directory <- dataset_dir[[dataset]][[level]]
      } else {
        warning(paste("Path not found in config for:", dataset, level))
        next  # Skip this iteration if the path is missing
      }
      
      # Generate dataset name
      prefix       <- substr(level, 1, 3)  # Extract first 3 letters
      dataset_name <- paste0(prefix, ".dataset.", dataset)

      # Read required files
      sample_tab  <- safe_read(file.path(directory, "sample_table.tsv") , sep = "\t", header = TRUE, row.names = 1) %>%
        mutate(Time = study_day, Rep = if_else(subject == "culi", 1, 2))
      tax_table   <- safe_read(file.path(directory, "tax_table.tsv")    , sep = "\t", header = TRUE, row.names = 1)
      otu_table   <- safe_read(file.path(directory, "feature_table.tsv"), sep = "\t", header = TRUE, row.names = 1)

      # Create dataset object
      if (data_type == "tax") {
        phylo_tree <- if (file.exists(file.path(directory, 
                                                "phylo_tree.tre"))) read.tree(file.path(directory, 
                                                                                        "phylo_tree.tre")) else NULL
        rep_fasta  <- if (file.exists(file.path(directory, 
                                                "rep_fasta.fasta"))) read.fasta(file.path(directory, 
                                                                                          "rep_fasta.fasta")) else NULL

        microtable_datasets$tax[[dataset_name]] <- microtable$new(
          sample_table = sample_tab,
          otu_table    = otu_table,
          tax_table    = tax_table,
          phylo_tree   = phylo_tree,
          rep_fasta    = rep_fasta,
          auto_tidy    = TRUE
        )
      } else {
        microtable_datasets$fun[[dataset_name]] <- microtable$new(
          sample_table = sample_tab,
          otu_table    = otu_table,
          tax_table    = tax_table,
          auto_tidy    = TRUE
        )
      }
    }
  }
}

```

```{r}
# Function to apply microeco operations
cal_basics_tax <- function(dataset) {
  
  dataset$tidy_dataset()
  
  # Compute abundance
  dataset$cal_abund()

  # Filter taxa
  dataset$filter_taxa(
    rel_abund      = methods_16s$loris$min_abund, 
    freq           = methods_16s$loris$min_freq, 
    include_lowest = methods_16s$loris$include_lowest
  )

  # Calculate alpha diversity
  dataset$cal_alphadiv(PD = methods_16s$loris$alpha_pd)

  # Calculate beta diversity
  dataset$cal_betadiv(
    unifrac = methods_16s$loris$unifrac, 
    method  = methods_16s$loris$betadiv
  )

  return(dataset) # Return modified dataset
}
```

```{r, message = FALSE}
# Loop through all datasets and apply functions
microtable_datasets$tax <-  map(microtable_datasets$tax, \(x) cal_basics_tax(x))
```


```{r}
# Function to apply microeco operations
cal_basics_fun <- function(dataset) {
  
  dataset$tidy_dataset()
  
  # Compute abundance
  dataset$cal_abund()

  # Filter taxa
  dataset$filter_taxa(
    rel_abund      = methods_16s$loris$min_abund, 
    freq           = methods_16s$loris$min_freq, 
    include_lowest = methods_16s$loris$include_lowest
  )

  # Calculate alpha diversity
  dataset$cal_alphadiv()

  # Calculate beta diversity
  dataset$cal_betadiv(method  = methods_16s$loris$betadiv)

  return(dataset) # Return modified dataset
}

```

```{r, message = FALSE}
# Loop through all datasets and apply functions
microtable_datasets$fun <-  map(microtable_datasets$fun, \(x) cal_basics_fun(x))
```

```{r}
microtables <- list_flatten(microtable_datasets, name_spec = "{inner}")
```



# Exploring Time-Series Analyses

## BEEM as a Suitable Approach {.tabset}

BEEM (**Bayesian inference of Ecological interactions from Microbiome time-series data**) is a computational approach that estimates species interactions and dynamic relationships in microbial communities over time. Unlike beemStatic, which is geared toward cross-sectional datasets, **BEEM** is specifically designed for **time-series microbiome data**, making it a better fit for our study.
  - Daily samples collected from two individuals over one year provide a true time-series dataset, which is ideal for BEEM.
  - **Metadata includes key covariates**: We have multiple independent variables that change over time (e.g., diet, supplements, subject health status, enclosure conditions), which can be incorporated into BEEM to explore how microbiome dynamics are influenced by these factors.
  - **BEEM is designed for non-stationary interactions**: The microbial interactions in our dataset likely change over time due to diet shifts, health interventions, or environmental changes. BEEM models these dynamic interactions rather than assuming a static microbial network.
  
### Some of Our Options with BEEM

1.	**Infer Microbial Interactions Over Time**
  - BEEM fits a **generalized Lotka-Volterra (gLV) model**, which describes how different microbial taxa interact (competition, mutualism, predation).
  - It identifies **key players** (dominant taxa) and how their populations influence each other across time.
2.	**Estimate the Influence of External Factors**
  - BEEM allows incorporation of **time-dependent covariates** (e.g., diet composition, antibiotic use, enclosure conditions) to test their effects on microbiome dynamics.
  - In our case, it could reveal whether changes in **diet composition, supplements, or health events** significantly impact microbial interactions.
3.	**Predict Future Microbiome Dynamics**
  - If we provide a subset of the data, BEEM can **forecast** future microbial shifts based on observed patterns.
4.	**Distinguish Individual-Specific Effects**
  - Since we have two subjects, BEEM could estimate whether **subject-specific factors (e.g., individual health, genetics, or behaviors)** contribute to differences in microbiome dynamics.
  
### Prepare Time-Series Dataset

>For our sample table to work with the trans_ts dataset class:  
>*"Two columns with exact names in sample_table are necessary; one is 'Time', which is the time point and should be the numeric class; the other is 'Rep', which represents the biological replicates and is also numeric class. If no replicates, use 1 to represent 1 replicate."*  

#### Trans_ts Class Conversion

>Note that here I am going to increase our filtering threshold to 0.01. This algorithm can't handle low abundance taxa and zero values as much as others, so this will improve its efficiency.

```{r}
prefixes    <- c("spe", "gen", "fam", "ord", "cla", "phy", "keg", "fpt", "njc")
sets       <- c("main", "culi", "warb")
ts.objects <- list()

ts_new <- function(dataset) {
  trans_ts$new(dataset = dataset, filter_thres = 0.01)
}



for (set in sets) {
  for (prefix in prefixes) {

    dataset_name <- paste0(prefix, ".dataset.", set)
    ts_name      <- paste0(prefix, ".ts.", set)
       
    dataset_obj <- microtables[[dataset_name]]

    if (!is.null(dataset_obj)) {
      ts.objects[[ts_name]] <- ts_new(dataset_obj)  # Store trans_ts object
    } else {
      warning(paste("Dataset object not found for:", dataset_name))
    }
  }
}
```

### Predict Biomass {.tabset}

>*This function predicts total microbial biomass using the Expectation-Maximization (EM) algorithm from BEEM. It adjusts for relative abundances and estimates total biomass without requiring absolute quantification.*  
  
**Note: Like the functional redundancy algorithm with Tax4fun2, this chunk can be quite memory-intensive and move slowly. You may want to consider running this as a background job.**

```{r, message = FALSE}
ts_biomass <- function(dataset) {
  dataset$cal_biomass(ncpu = 6)
  return(dataset)
}


map(ts.objects, \(x) ts_biomass(x))


```


### Calculate Network

```{r}
ts_network <- function(dataset) {
  dataset$cal_network()
}

map(ts.objects, \(x) ts_network(x))
```



### Calculate Network Modules

```{r}
ts_module <- function(dataset) {
  dataset$calmodule()
}

map(ts.objects, \(x) ts_module(x))
```

### Save Network

Save network as gexf style, which can be opened by [Gephi](https://gephi.org/).

```{r}
ts_module <- function(dataset, filepath) {
  dataset$save_network(filepath = filepath)
}

imap(ts.objects, \(x, idx) ts_module(x, paste0("visuals/gephi/", idx, ".gexf")))

```

### Plot Network

```{r}
ts_plot_network <- function(dataset) {
  dataset$plot_network(method = "networkD3")
}

map(ts.objects, \(x) ts_plot_network(x))

```


### Plot Taxa Roles

#### Get Node Table

```{r}
ts_node <- function(dataset) {
  dataset$get_node_table()
}

map(ts.objects, \(x) ts_node(x))

```

#### Plot

```{r}
ts_plot_network <- function(dataset) {
  dataset$plot_network(method = "networkD3")
}

map(ts.objects, \(x) ts_plot_network(x))

```

```{r}
# Convert list to global environment variables
list2env(ts.objects, envir = .GlobalEnv)
```


# Linear Models

## Independent Variables

```{r}
diet_vars <- list(
"diet_name"	,
"total_mg"	,
"total_kcal"	,
"total_mg_dry"	,
"protein_fed"	,
"fat_fed"	,
"CHO_fed"	,
"mineral_fed"
)

meds_supplements <- list(
"probiotic"	,
"fiber"	,
"steroid"	,
"antibiotic"	,
"antidiarrheal"	
)

random_effects <- list(
"study_day"	,
"subject"	,
"holding"	,
"pair_access"	,
"warb_status"	
)
```


## Dependent Variables

```{r}
inflammation <- list("bristol_mean")
abundance    <- list("rel_abundance")
alpha_diversity <- list()
```


## Generalized Linear Mixed Models (GLMMs) {.tabset}

GLMMs are an extension of generalized linear models (GLMs), allowing for the inclusion of random effects to account for hierarchical or nested data structures.  

### Designing and Running the Model

```{r}
effects_fixed <- list("diet_name", 
                      "probiotic", "fiber", steroid, total_mg, total_kcal, warb_status, subject_age, Sex)
```


```{r}
glmmA <- c()
```




### Background
  
#### When to Use GLMMs

1.  **Hierarchical Data**: For example, when samples are nested within subjects, and subjects are nested within treatment groups.
2.  **Overdispersion**: When the variance in the data is greater than expected under a traditional GLM.
3.  **Non-Normal Response Variables**: For example:
  - Binomial data (e.g., presence/absence of a microbial taxon).
  - Poisson data (e.g., counts of microbial reads).

### Structure of a GLMM

A GLMM has the form:  

$g(E(y)) = X\beta + Zb$
 
  
- $g(E(y))$: A link function (e.g., log, logit) that relates the expected value of the response variable y to the linear predictors.
- $X\beta$: Fixed effects (predictors like treatment, time, etc.).
- $Zb$: Random effects (e.g., subject-specific effects).


#### Common Applications

- **Microbial Abundance:** Using Poisson or negative binomial distributions to model raw or normalized count data.
- **Presence/Absence:** Modeling binary outcomes for specific taxa (e.g., the presence of a pathogenic species).
- **Diversity Metrics:** Modeling alpha diversity indices as the response variable while accounting for repeated measures or nested study designs.

#### How GLMMs Work for Microbiome Data

A GLMM can handle situations like:  

- **Raw Counts**: Model the abundance of a specific taxon across samples using Poisson or negative binomial distributions.
- **Taxa Presence/Absence**: Use a logistic regression model to predict whether a taxon is present or absent based on variables like diet, time, or environmental factors.

#### Why GLMMs Are Useful

- They allow us to adjust for random effects, like individual variation between subjects or differences between sequencing runs.
- GLMMs can account for overdispersion, which is common in count data like microbial abundances.
