---
title: "Loris Microbiome Project Results Overview - IN PROGRESS"
author: "Alicia Rich"
output:
  html_document:
    theme:
      bootswatch: litera
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    code_folding: "show"
    fig_caption: true
    df_print: paged
params:
  sampleset: "loris"
                     
---

```{r, message = FALSE}
global             <- config::get(config = "default")

here::i_am("ExploreResults_LorisMicrobiome.Rmd")
source(here::here(global$setup))

for (file in micro$micro_scripts) {
  source(here(file))
}

source(here(path$metadata$key))
source(here(path$metadata$factors))

dataset_dir <- path$microeco$dataset

theme_set(theme_classic())
thematic_rmd()
thematic_on(accent = "#8785B2FF", fg = "black")
```

# Read in Data

I have written several custom functions to expedite some of the functions that I reuse multiple times for data sets across different sample and taxon subsets. The loop below will use one of those functions to read the microeco datasets that I built using the [MicroEcoDataPrep](MicroEcoDataPrep.html) script.  
  
This code makes use of the dataset paths referenced in my config.yaml file. To see the full path (relative to the repository base directory), refer to the relative syntax in this script and the config file below.  

```{r, echo = FALSE}
page_fluid(
    accordion(
      open = FALSE,
      accordion_panel(
        "Show/Hide Config File (config.yml)",
        tagList(tags$pre(includeText("config.yml")))
    )
  )
)
```



```{r}
# Define dataset categories
dataset_types <- c("tax", "function")
tax_levels    <- c("species", "genus", "family", "order", "class", "phylum")
func_levels   <- c("kegg", "fpt", "njc")
datasets      <- c("main", "culi", "warb")

# Create an empty list to store all datasets
microtable_datasets <- list()

# Helper function to safely read files
safe_read <- function(file, ...) {
  if (file.exists(file)) {
    return(read.table(file, ...))
  } else {
    warning(paste("File missing:", file))
    return(NULL)
  }
}

# Loop through dataset types (taxonomic and functional)
for (data_type in dataset_types) {
  levels <- if (data_type == "tax") tax_levels else func_levels
  
  for (level in levels) {
    for (dataset in datasets) {
      # Extract dataset path from config
      if (!is.null(dataset_dir[[dataset]][[level]])) {
        directory <- dataset_dir[[dataset]][[level]]
      } else {
        warning(paste("Path not found in config for:", dataset, level))
        next  # Skip this iteration if the path is missing
      }
      
      # Generate dataset name
      prefix       <- substr(level, 1, 3)  # Extract first 3 letters
      dataset_name <- paste0(prefix, ".dataset.", dataset)

      # Read required files
      sample_tab  <- safe_read(file.path(directory, "sample_table.tsv") , sep = "\t", header = TRUE, row.names = 1) %>%
        mutate(Time = study_day, Rep = if_else(subject == "culi", 1, 2))
      tax_table   <- safe_read(file.path(directory, "tax_table.tsv")    , sep = "\t", header = TRUE, row.names = 1)
      otu_table   <- safe_read(file.path(directory, "feature_table.tsv"), sep = "\t", header = TRUE, row.names = 1)

      # Create dataset object
      if (data_type == "tax") {
        phylo_tree <- if (file.exists(file.path(directory, 
                                                "phylo_tree.tre"))) read.tree(file.path(directory, 
                                                                                        "phylo_tree.tre")) else NULL
        rep_fasta  <- if (file.exists(file.path(directory, 
                                                "rep_fasta.fasta"))) read.fasta(file.path(directory, 
                                                                                          "rep_fasta.fasta")) else NULL

        microtable_datasets$tax[[dataset_name]] <- microtable$new(
          sample_table = sample_tab,
          otu_table    = otu_table,
          tax_table    = tax_table,
          phylo_tree   = phylo_tree,
          rep_fasta    = rep_fasta,
          auto_tidy    = TRUE
        )
      } else {
        microtable_datasets$fun[[dataset_name]] <- microtable$new(
          sample_table = sample_tab,
          otu_table    = otu_table,
          tax_table    = tax_table,
          auto_tidy    = TRUE
        )
      }
    }
  }
}

```

```{r}
# Function to apply microeco operations
cal_basics_tax <- function(dataset) {
  
  dataset$tidy_dataset()
  
  # Compute abundance
  dataset$cal_abund()

  # Filter taxa
  dataset$filter_taxa(
    rel_abund      = methods_16s$loris$min_abund, 
    freq           = methods_16s$loris$min_freq, 
    include_lowest = methods_16s$loris$include_lowest
  )

  # Calculate alpha diversity
  dataset$cal_alphadiv(PD = methods_16s$loris$alpha_pd)

  # Calculate beta diversity
  dataset$cal_betadiv(
    unifrac = methods_16s$loris$unifrac, 
    method  = methods_16s$loris$betadiv
  )

  return(dataset) # Return modified dataset
}
```

```{r, message = FALSE}
# Loop through all datasets and apply functions
microtable_datasets$tax <-  map(microtable_datasets$tax, \(x) cal_basics_tax(x))
```


```{r}
# Function to apply microeco operations
cal_basics_fun <- function(dataset) {
  
  dataset$tidy_dataset()
  
  # Compute abundance
  dataset$cal_abund()

  # Filter taxa
  dataset$filter_taxa(
    rel_abund      = methods_16s$loris$min_abund, 
    freq           = methods_16s$loris$min_freq, 
    include_lowest = methods_16s$loris$include_lowest
  )

  # Calculate alpha diversity
  dataset$cal_alphadiv()

  # Calculate beta diversity
  dataset$cal_betadiv(method  = methods_16s$loris$betadiv)

  return(dataset) # Return modified dataset
}

```

```{r}
# Loop through all datasets and apply functions
microtable_datasets$fun <-  map(microtable_datasets$fun, \(x) cal_basics_fun(x))
```

```{r}
microtables <- list_flatten(microtable_datasets, name_spec = "{inner}")
```



# Exploring Time-Series Analyses

## BEEM as a Suitable Approach {.tabset}

BEEM (**Bayesian inference of Ecological interactions from Microbiome time-series data**) is a computational approach that estimates species interactions and dynamic relationships in microbial communities over time. Unlike beemStatic, which is geared toward cross-sectional datasets, **BEEM** is specifically designed for **time-series microbiome data**, making it a better fit for our study.
  - Daily samples collected from two individuals over one year provide a true time-series dataset, which is ideal for BEEM.
  - **Metadata includes key covariates**: We have multiple independent variables that change over time (e.g., diet, supplements, subject health status, enclosure conditions), which can be incorporated into BEEM to explore how microbiome dynamics are influenced by these factors.
  - **BEEM is designed for non-stationary interactions**: The microbial interactions in our dataset likely change over time due to diet shifts, health interventions, or environmental changes. BEEM models these dynamic interactions rather than assuming a static microbial network.
  
### Some of Our Options with BEEM

1.	**Infer Microbial Interactions Over Time**
  - BEEM fits a **generalized Lotka-Volterra (gLV) model**, which describes how different microbial taxa interact (competition, mutualism, predation).
  - It identifies **key players** (dominant taxa) and how their populations influence each other across time.
2.	**Estimate the Influence of External Factors**
  - BEEM allows incorporation of **time-dependent covariates** (e.g., diet composition, antibiotic use, enclosure conditions) to test their effects on microbiome dynamics.
  - In our case, it could reveal whether changes in **diet composition, supplements, or health events** significantly impact microbial interactions.
3.	**Predict Future Microbiome Dynamics**
  - If we provide a subset of the data, BEEM can **forecast** future microbial shifts based on observed patterns.
4.	**Distinguish Individual-Specific Effects**
  - Since we have two subjects, BEEM could estimate whether **subject-specific factors (e.g., individual health, genetics, or behaviors)** contribute to differences in microbiome dynamics.
  
### First use: Setting up BEEM

MicroEco's tutorial [guided us through installation of several dependencies, including BEEM-static](https://chiliubio.github.io/microeco_tutorial/intro.html#dependence), but to work with true longitudinal data like this, we want to use the original BEEM package instead. This is where microeco's [*mecodev* package](https://chiliubio.github.io/microeco_tutorial/mecodev-package.html) comes in handy. Mecodev provides a set of extended classes based on the microeco package, including *trans_ts*, a class designed for handling time-series data.

#### Install mecodev and dependencies

>I am following the linux/mac instructions. See the microeco tutorial for windows-specific code.

```{r, eval = FALSE}
# If devtools package is not installed, first install it
install.packages("devtools")
```

##### mecodev

```{r, eval = FALSE}
devtools::install_github("ChiLiubio/mecodev")
```

##### Dependencies

```{r, eval = FALSE}
# For linux or mac
install.packages("doMC")
# Then install the following packages
install.packages("lokern")
install.packages("monomvn")
install.packages("pspline")
devtools::install_github('csb5/beem')
```

### Prepare Time-Series Dataset

>For our sample table to work with the trans_ts dataset class:  
>*"Two columns with exact names in sample_table are necessary; one is 'Time', which is the time point and should be the numeric class; the other is 'Rep', which represents the biological replicates and is also numeric class. If no replicates, use 1 to represent 1 replicate."*  

#### Trans_ts Class Conversion

```{r}
prefixes    <- c("spe", "gen", "fam", "ord", "cla", "phy", "keg", "fpt", "njc")
sets       <- c("main", "culi", "warb")
ts.objects <- list()

ts_new <- function(dataset) {
  trans_ts$new(dataset = dataset)
}



for (set in sets) {
  for (prefix in prefixes) {

    dataset_name <- paste0(prefix, ".dataset.", set)
    ts_name      <- paste0(prefix, ".ts.", set)
       
    dataset_obj <- microtables[[dataset_name]]

    if (!is.null(dataset_obj)) {
      ts.objects[[ts_name]] <- ts_new(dataset_obj)  # Store trans_ts object
    } else {
      warning(paste("Dataset object not found for:", dataset_name))
    }
  }
}
```

### Predict Biomass

>*This function predicts total microbial biomass using the Expectation-Maximization (EM) algorithm from BEEM. It adjusts for relative abundances and estimates total biomass without requiring absolute quantification.*  
  
**Note: Like the functional redundancy algorithm with Tax4fun2, this chunk can be quite memory-intensive and move slowly. You may want to consider running this as a background job.**



```{r}
ts_biomass <- function(dataset) {
  dataset$cal_biomass(ncpu = 4)
  return(dataset)
}


map(ts.objects, \(x) ts_biomass(x))


```

```{r}
# Convert list to global environment variables
list2env(ts.objects, envir = .GlobalEnv)
```


### Calculate Network

```{r}
ts_network <- function(dataset) {
  dataset$cal_network()
}

map(ts.objects, \(x) ts_network(x))
```

```{r}
fam.ts.main$cal_biomass(ncpu = 4)
```


### Calculate Network Modules

```{r}
ts_module <- function(dataset) {
  dataset$calmodule()
}

map(ts.objects, \(x) ts_module(x))
```

### Save Network

Save network as gexf style, which can be opened by [Gephi](https://gephi.org/).

```{r}
ts_module <- function(dataset, filepath) {
  dataset$save_network(filepath = filepath)
}

imap(ts.objects, \(x, idx) ts_module(x, paste0("visuals/gephi/", idx, ".gexf")))

```

### Plot Network

```{r}
ts_plot_network <- function(dataset) {
  dataset$plot_network(method = "networkD3")
}

map(ts.objects, \(x) ts_plot_network(x))

```


### Plot Taxa Roles

#### Get Node Table

```{r}
ts_node <- function(dataset) {
  dataset$get_node_table()
}

map(ts.objects, \(x) ts_node(x))

```

#### Plot

```{r}
ts_plot_network <- function(dataset) {
  dataset$plot_network(method = "networkD3")
}

map(ts.objects, \(x) ts_plot_network(x))

```


